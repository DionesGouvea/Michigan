{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObj8bUMUgT6cyrOJx596Kj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZt_yZ9hPxiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b18179-b9da-4cfc-b5f1-2ff0c1d2b17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 178\n",
            "1 182\n",
            "2 177\n",
            "3 183\n",
            "4 181\n",
            "5 182\n",
            "6 181\n",
            "7 179\n",
            "8 174\n",
            "9 180\n"
          ]
        }
      ],
      "source": [
        "%matplotlib notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "dataset = load_digits()\n",
        "X, y = dataset.data, dataset.target\n",
        "\n",
        "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
        "    print(class_name,class_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando o dataset load_digits e printando a quantidade de cada valor da variavel target. \n"
      ],
      "metadata": {
        "id": "CM7uU8m_J8-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criando um dataset desbalanceado usando a base acima   \n",
        "# Negative class (0) is 'not digit 1' \n",
        "# Positive class (1) is 'digit 1'\n",
        "y_binary_imbalanced = y.copy()\n",
        "y_binary_imbalanced[y_binary_imbalanced != 1] = 0 #todos os valores diferentes de 1 serão 0 \n",
        "\n",
        "#printando os valores \n",
        "print('Original labels:\\t', y[1:30])\n",
        "print('New binary labels:\\t', y_binary_imbalanced[1:30])"
      ],
      "metadata": {
        "id": "v8b5YjoTP6r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7b4ac8-f388-40ec-edc4-e7b9d08632b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original labels:\t [1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
            "New binary labels:\t [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.bincount(y_binary_imbalanced)  #veja que o numero de casos 1 permance o mesmo. "
      ],
      "metadata": {
        "id": "4Jiiw4gXYPA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13117fb-a7bf-405e-da2c-f34ffed416c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1615,  182])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "\n",
        "#aplicando o svm e obtendo a acuracia do modelo \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
        "svm.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4z79JMtK0lj",
        "outputId": "f161d10b-c3bc-4afd-cfe4-e038d64b2639"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9955555555555555"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que foi obtdido uma acuracia de 99.5% mas temos que lembrar que a acuracia e o quanto nossas previsões acertaram, e por possuirmos um conjunto de dados desbalanceados e facil obter valores altos.\n",
        " "
      ],
      "metadata": {
        "id": "doQY7rEVMCLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dummy Classifiers"
      ],
      "metadata": {
        "id": "N8hIZU0CMB2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# a classe negativa 0 é a mais frequente \n",
        "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "# usando o dummy com a estrategia most_frequent ele vai prever todos nossos valores como a classe mais frequente \n",
        "y_dummy_predictions = dummy_majority.predict(X_test)\n",
        "\n",
        "y_dummy_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTwdncmvMqyT",
        "outputId": "7ee7c0c6-22fb-496e-d8a5-0e6b7e00e5d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que todos os valores foram previstos como zero "
      ],
      "metadata": {
        "id": "P2-CWlrwNKMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_majority.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36xhRz6_MrP9",
        "outputId": "88ffc0d0-9f5e-4054-b144-266eab54d884"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9044444444444445"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mesmo todos os valores sendo previstos como zero obtvemos uma acuracia de 90% normalmente queremos usar o most_frequency para usar como comparação quando rodarmos nossas outras metricas em modelos mais eficientes, fica claro que obter uma acuracia de 90% mesmo classificando todas as classes como negativas que nosso conjunto de dados é desbalanceado e acuracy não é a mais indicada\n",
        "\n"
      ],
      "metadata": {
        "id": "8m-A51njNZ1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrices"
      ],
      "metadata": {
        "id": "oQbH3ayDQ9kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Negative class (0) is most frequent\n",
        "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "y_majority_predicted = dummy_majority.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_majority_predicted)\n",
        "\n",
        "print('Most frequent class (dummy classifier)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaYtRODhNXu7",
        "outputId": "66dda8f6-f024-4ea5-ab6c-d632b77a0132"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent class (dummy classifier)\n",
            " [[407   0]\n",
            " [ 43   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "como ja tinha visto anteriormente, todos os dados foram classificados como negativos temos 43 casos positivos como é possivel ver "
      ],
      "metadata": {
        "id": "0YxLssVYRC98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# produces random predictions w/ same class proportion as training set\n",
        "dummy_classprop = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
        "y_classprop_predicted = dummy_classprop.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_classprop_predicted)\n",
        "\n",
        "print('Random class-proportional prediction (dummy classifier)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4_So4CVRBgD",
        "outputId": "0fd0d572-b479-493f-ed79-7e327d433375"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random class-proportional prediction (dummy classifier)\n",
            " [[368  39]\n",
            " [ 40   3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora usando a estrategia de previsões aleatorias, ele esta usando a mesma proporção de valores de X_train e prevendo ou seja, se o conjunto de treinamento tiver 60% de amostras de classe 1 e 40% de amostras de classe 0, a estratégia \"stratified\" produzirá previsões aleatórias com 60% de amostras de classe 1 e 40% de amostras de classe 0. "
      ],
      "metadata": {
        "id": "Jox58gRxTvOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "svm_predicted = svm.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, svm_predicted)\n",
        "\n",
        "print('Support vector machine classifier (linear kernel, C=1)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfg-ckpiTOUU",
        "outputId": "f2dc6aaa-759e-4ab9-d1d5-8ba7ff58bc21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support vector machine classifier (linear kernel, C=1)\n",
            " [[402   5]\n",
            " [  5  38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando agora o SVC linear obtvemos um predict mais proximo dos dados reais, sendo que foram previsto apenas 5 casos como falso negatito e falso positivo "
      ],
      "metadata": {
        "id": "EeIsqlX8Ud_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metricas de validação para problemas de classificação binaria "
      ],
      "metadata": {
        "id": "NWTnxAnJccWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
        "tree_predicted = dt.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, tree_predicted)\n",
        "\n",
        "print('Decision tree classifier (max_depth = 2)\\n', confusion)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
        "# Precision = TP / (TP + FP)\n",
        "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
        "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
        "print('\\nAccuracy: {:.2f}'.format(accuracy_score(y_test, tree_predicted)))\n",
        "print('Precision: {:.2f}'.format(precision_score(y_test, tree_predicted)))\n",
        "print('Recall: {:.2f}'.format(recall_score(y_test, tree_predicted)))\n",
        "print('F1: {:.2f}'.format(f1_score(y_test, tree_predicted)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ_GZ53UUZmq",
        "outputId": "270db835-9b0d-40c7-d6bf-628924f01949"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree classifier (max_depth = 2)\n",
            " [[400   7]\n",
            " [ 17  26]]\n",
            "\n",
            "Accuracy: 0.95\n",
            "Precision: 0.79\n",
            "Recall: 0.60\n",
            "F1: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "analisando as metricas podemos ver que a acuracia esta alta por se tratar de dados desbalanceados, a precisão esta sendo afetada por não ter previsto o numero total possivel e também por ter previsto valores positivos que de fato não são positivos, o recall esta sendo afetado pelos falsos negativos, e o F1 é a combinação entre precisão e recall"
      ],
      "metadata": {
        "id": "MkjYRAY0dYYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined report with all above metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, tree_predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn-IfNvcdX3p",
        "outputId": "2d2864c2-d220-4267-dde0-88dd511de365"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       407\n",
            "           1       0.79      0.60      0.68        43\n",
            "\n",
            "    accuracy                           0.95       450\n",
            "   macro avg       0.87      0.79      0.83       450\n",
            "weighted avg       0.94      0.95      0.94       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note que ao usar o classification_report ele traz o support que nada mais é que a quantidade de dados da nossa variavel target. ele também divide as classes e retorna as metricas para cada uma individualmente. "
      ],
      "metadata": {
        "id": "7OXLxundeVNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Random class-proportional (dummy)\\n', \n",
        "      classification_report(y_test, y_classprop_predicted, target_names=['not 1', '1']))\n",
        "print('SVM\\n', \n",
        "      classification_report(y_test, svm_predicted, target_names = ['not 1', '1']))\n",
        "\n",
        "print('Decision tree\\n', \n",
        "      classification_report(y_test, tree_predicted, target_names = ['not 1', '1']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m806a3M4clRj",
        "outputId": "e126c740-2a59-4e23-df85-d009e54b6248"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random class-proportional (dummy)\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.90      0.90      0.90       407\n",
            "           1       0.07      0.07      0.07        43\n",
            "\n",
            "    accuracy                           0.82       450\n",
            "   macro avg       0.49      0.49      0.49       450\n",
            "weighted avg       0.82      0.82      0.82       450\n",
            "\n",
            "SVM\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.99      0.99      0.99       407\n",
            "           1       0.88      0.88      0.88        43\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.94      0.94      0.94       450\n",
            "weighted avg       0.98      0.98      0.98       450\n",
            "\n",
            "Decision tree\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.96      0.98      0.97       407\n",
            "           1       0.79      0.60      0.68        43\n",
            "\n",
            "    accuracy                           0.95       450\n",
            "   macro avg       0.87      0.79      0.83       450\n",
            "weighted avg       0.94      0.95      0.94       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podesmos perceber que o modelo que obteve as melhores metricas foi o SVM "
      ],
      "metadata": {
        "id": "YJJk44PHfVPM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqwvDHqDe7Mx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}