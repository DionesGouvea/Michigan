{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGB87kZ75wPVjg4nhMsE7i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos de Regressão Linear \n",
        "### Linear Regression"
      ],
      "metadata": {
        "id": "EDJyAOAiBDke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1,random_state = 0)\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print('linear model coeff (w): {}'\n",
        "     .format(linreg.coef_)) #so temos um coef pois so temos 1 feature \n",
        "print('linear model intercept (b): {:.3f}'\n",
        "     .format(linreg.intercept_)) #é o valor que da nossa variavel target quando todas as nossas features na reta são (x = 0) \n",
        "\n",
        "#o score explica o quanto nosso modelo esta acertando, ou quanto nosso modelo esta sendo capas de entender nossos dados para prever o valor \n",
        "print('R-squared score (training): {:.3f}'\n",
        "     .format(linreg.score(X_train, y_train)))\n",
        "print('R-squared score (test): {:.3f}'\n",
        "     .format(linreg.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxUpGSQKA_WB",
        "outputId": "bc9afacb-f661-481a-c8b8-1456ee76ca82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear model coeff (w): [45.71]\n",
            "linear model intercept (b): 148.446\n",
            "R-squared score (training): 0.679\n",
            "R-squared score (test): 0.492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regressão linear: Plot Exemplo"
      ],
      "metadata": {
        "id": "rTpXHN0_Jhh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "plt.scatter(X_R1, y_R1, marker= 'o', s=50, alpha=0.8)\n",
        "plt.plot(X_R1, linreg.coef_ * X_R1 + linreg.intercept_, 'r-')\n",
        "plt.title('Least-squares linear regression')\n",
        "plt.xlabel('Feature value (x)')\n",
        "plt.ylabel('Target value (y)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-h3lBtz4JhTZ",
        "outputId": "388a114c-2a06-4d2e-8fef-8bcc9b4702a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
        "                                                   random_state = 0)\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print('Crime dataset')\n",
        "print('linear model intercept: {}'\n",
        "     .format(linreg.intercept_))\n",
        "print('linear model coeff:\\n{}'\n",
        "     .format(linreg.coef_))\n",
        "print('R-squared score (training): {:.3f}'\n",
        "     .format(linreg.score(X_train, y_train)))\n",
        "print('R-squared score (test): {:.3f}'\n",
        "     .format(linreg.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU4kKWQsDnuu",
        "outputId": "40d735ec-c99e-44c8-8f14-ac785350acbb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crime dataset\n",
            "linear model intercept: -1728.130672601781\n",
            "linear model coeff:\n",
            "[ 1.62e-03 -9.43e+01  1.36e+01 -3.13e+01 -8.15e-02 -1.69e+01 -2.43e-03\n",
            "  1.53e+00 -1.39e-02 -7.72e+00  2.28e+01 -5.66e+00  9.35e+00  2.07e-01\n",
            " -7.43e+00  9.66e-03  4.38e-03  4.80e-03 -4.46e+00 -1.61e+01  8.83e+00\n",
            " -5.07e-01 -1.42e+00  8.18e+00 -3.87e+00 -3.54e+00  4.49e+00  9.31e+00\n",
            "  1.74e+02  1.18e+01  1.51e+02 -3.30e+02 -1.35e+02  6.95e-01 -2.38e+01\n",
            "  2.77e+00  3.82e-01  4.39e+00 -1.06e+01 -4.92e-03  4.14e+01 -1.16e-03\n",
            "  1.19e+00  1.75e+00 -3.68e+00  1.60e+00 -8.42e+00 -3.80e+01  4.74e+01\n",
            " -2.51e+01 -2.88e-01 -3.66e+01  1.90e+01 -4.53e+01  6.83e+02  1.04e+02\n",
            " -3.29e+02 -3.14e+01  2.74e+01  5.12e+00  6.92e+01  1.98e-02 -6.12e-01\n",
            "  2.65e+01  1.01e+01 -1.59e+00  2.24e+00  7.38e+00 -3.14e+01 -9.78e-05\n",
            "  5.02e-05 -3.48e-04 -2.50e-04 -5.27e-01 -5.17e-01 -4.10e-01  1.16e-01\n",
            "  1.46e+00 -3.04e-01  2.44e+00 -3.66e+01  1.41e-01  2.89e-01  1.77e+01\n",
            "  5.97e-01  1.98e+00 -1.36e-01 -1.85e+00]\n",
            "R-squared score (training): 0.673\n",
            "R-squared score (test): 0.496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge regression\n",
        "\n",
        "A Regressão de Ridge é um tipo de regularização de regressão linear que adiciona uma penalidade aos coeficientes para evitar overfitting (sobreajuste). Ela é uma variação da Regressão Linear tradicional, onde a função de custo é ajustada para minimizar a soma dos quadrados dos erros"
      ],
      "metadata": {
        "id": "vwU5LQaNK3gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
        "                                                   random_state = 0)\n",
        "\n",
        "linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
        "\n",
        "print('Crime dataset')\n",
        "print('ridge regression linear model intercept: {}'\n",
        "     .format(linridge.intercept_))\n",
        "print('ridge regression linear model coeff:\\n{}'\n",
        "     .format(linridge.coef_))\n",
        "print('R-squared score (training): {:.3f}'\n",
        "     .format(linridge.score(X_train, y_train)))\n",
        "print('R-squared score (test): {:.3f}'\n",
        "     .format(linridge.score(X_test, y_test)))\n",
        "print('Number of non-zero features: {}'\n",
        "     .format(np.sum(linridge.coef_ != 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2gO7xgbK2vk",
        "outputId": "9dd41278-6e5a-46d4-9bff-b2e8bccad1c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crime dataset\n",
            "ridge regression linear model intercept: -3352.423035846137\n",
            "ridge regression linear model coeff:\n",
            "[ 1.95e-03  2.19e+01  9.56e+00 -3.59e+01  6.36e+00 -1.97e+01 -2.81e-03\n",
            "  1.66e+00 -6.61e-03 -6.95e+00  1.72e+01 -5.63e+00  8.84e+00  6.79e-01\n",
            " -7.34e+00  6.70e-03  9.79e-04  5.01e-03 -4.90e+00 -1.79e+01  9.18e+00\n",
            " -1.24e+00  1.22e+00  1.03e+01 -3.78e+00 -3.73e+00  4.75e+00  8.43e+00\n",
            "  3.09e+01  1.19e+01 -2.05e+00 -3.82e+01  1.85e+01  1.53e+00 -2.20e+01\n",
            "  2.46e+00  3.29e-01  4.02e+00 -1.13e+01 -4.70e-03  4.27e+01 -1.23e-03\n",
            "  1.41e+00  9.35e-01 -3.00e+00  1.12e+00 -1.82e+01 -1.55e+01  2.42e+01\n",
            " -1.32e+01 -4.20e-01 -3.60e+01  1.30e+01 -2.81e+01  4.39e+01  3.87e+01\n",
            " -6.46e+01 -1.64e+01  2.90e+01  4.15e+00  5.34e+01  1.99e-02 -5.47e-01\n",
            "  1.24e+01  1.04e+01 -1.57e+00  3.16e+00  8.78e+00 -2.95e+01 -2.33e-04\n",
            "  3.14e-04 -4.14e-04 -1.79e-04 -5.74e-01 -5.18e-01 -4.21e-01  1.53e-01\n",
            "  1.33e+00  3.85e+00  3.03e+00 -3.78e+01  1.38e-01  3.08e-01  1.57e+01\n",
            "  3.31e-01  3.36e+00  1.61e-01 -2.68e+00]\n",
            "R-squared score (training): 0.671\n",
            "R-squared score (test): 0.494\n",
            "Number of non-zero features: 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge regression with feature normalization\n",
        "Colocando todas as features dentro de uma mesma escala com scaler.fit antes de aplicar o ridge para garantir que todas as features seram tratadas de forma equitativa, e assim melhorar a precisão do modelo."
      ],
      "metadata": {
        "id": "Q1i4WfSHMeFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
        "                                                   random_state = 0)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
        "\n",
        "print('Crime dataset')\n",
        "print('ridge regression linear model intercept: {}'\n",
        "     .format(linridge.intercept_))\n",
        "print('ridge regression linear model coeff:\\n{}'\n",
        "     .format(linridge.coef_))\n",
        "print('R-squared score (training): {:.3f}'\n",
        "     .format(linridge.score(X_train_scaled, y_train)))\n",
        "print('R-squared score (test): {:.3f}'\n",
        "     .format(linridge.score(X_test_scaled, y_test)))\n",
        "print('Number of non-zero features: {}'\n",
        "     .format(np.sum(linridge.coef_ != 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAno19iPK_NO",
        "outputId": "480ee36a-ad54-4ea1-90f6-5d35aa2a27bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crime dataset\n",
            "ridge regression linear model intercept: 933.3906385044153\n",
            "ridge regression linear model coeff:\n",
            "[  88.69   16.49  -50.3   -82.91  -65.9    -2.28   87.74  150.95   18.88\n",
            "  -31.06  -43.14 -189.44   -4.53  107.98  -76.53    2.86   34.95   90.14\n",
            "   52.46  -62.11  115.02    2.67    6.94   -5.67 -101.55  -36.91   -8.71\n",
            "   29.12  171.26   99.37   75.07  123.64   95.24 -330.61 -442.3  -284.5\n",
            " -258.37   17.66 -101.71  110.65  523.14   24.82    4.87  -30.47   -3.52\n",
            "   50.58   10.85   18.28   44.11   58.34   67.09  -57.94  116.14   53.81\n",
            "   49.02   -7.62   55.14  -52.09  123.39   77.13   45.5   184.91  -91.36\n",
            "    1.08  234.09   10.39   94.72  167.92  -25.14   -1.18   14.6    36.77\n",
            "   53.2   -78.86   -5.9    26.05  115.15   68.74   68.29   16.53  -97.91\n",
            "  205.2    75.97   61.38  -79.83   67.27   95.67  -11.88]\n",
            "R-squared score (training): 0.615\n",
            "R-squared score (test): 0.599\n",
            "Number of non-zero features: 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ridge regression with regularization parameter: alpha\n",
        "\n",
        "Usando alpha com valores diferentes para treinar o scaler e encontrar qual o melhor valor para normalizar os dados de que quando treinarmos o ridge se obtenha a melhor generalização dos dados"
      ],
      "metadata": {
        "id": "bltU-Mx8OsUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
        "for this_alpha in [0, 1, 10, 20, 50, 100, 1000]:\n",
        "    linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
        "    r2_train = linridge.score(X_train_scaled, y_train)\n",
        "    r2_test = linridge.score(X_test_scaled, y_test)\n",
        "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
        "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
        "r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
        "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH7PmFW8MgEA",
        "outputId": "86edfcb9-b8c6-46a8-dedd-acd0d48fe65c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge regression: effect of alpha regularization parameter\n",
            "\n",
            "Alpha = 0.00\n",
            "num abs(coeff) > 1.0: 88, r-squared training: 0.67, r-squared test: 0.50\n",
            "\n",
            "Alpha = 1.00\n",
            "num abs(coeff) > 1.0: 87, r-squared training: 0.66, r-squared test: 0.56\n",
            "\n",
            "Alpha = 10.00\n",
            "num abs(coeff) > 1.0: 87, r-squared training: 0.63, r-squared test: 0.59\n",
            "\n",
            "Alpha = 20.00\n",
            "num abs(coeff) > 1.0: 88, r-squared training: 0.61, r-squared test: 0.60\n",
            "\n",
            "Alpha = 50.00\n",
            "num abs(coeff) > 1.0: 86, r-squared training: 0.58, r-squared test: 0.58\n",
            "\n",
            "Alpha = 100.00\n",
            "num abs(coeff) > 1.0: 87, r-squared training: 0.55, r-squared test: 0.55\n",
            "\n",
            "Alpha = 1000.00\n",
            "num abs(coeff) > 1.0: 84, r-squared training: 0.31, r-squared test: 0.30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso regression\n",
        "A Regressão Lasso (Least Absolute Shrinkage and Selection Operator) é um tipo de regularização de regressão linear que adiciona uma penalidade aos coeficientes para evitar overfitting (sobreajuste) e selecionar automaticamente algumas features. Ele é uma variação da Regressão Linear tradicional, onde a função de custo é ajustada para minimizar a soma dos quadrados dos erros\n"
      ],
      "metadata": {
        "id": "mXOXvaOAPyDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
        "                                                   random_state = 0)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "linlasso = Lasso(alpha=2.0, max_iter = 10000).fit(X_train_scaled, y_train)\n",
        "\n",
        "print('Crime dataset')\n",
        "print('lasso regression linear model intercept: {}'\n",
        "     .format(linlasso.intercept_))\n",
        "print('lasso regression linear model coeff:\\n{}'\n",
        "     .format(linlasso.coef_))\n",
        "print('Non-zero features: {}'\n",
        "     .format(np.sum(linlasso.coef_ != 0)))\n",
        "print('R-squared score (training): {:.3f}'\n",
        "     .format(linlasso.score(X_train_scaled, y_train)))\n",
        "print('R-squared score (test): {:.3f}\\n'\n",
        "     .format(linlasso.score(X_test_scaled, y_test)))\n",
        "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
        "\n",
        "for e in sorted (list(zip(list(X_crime), linlasso.coef_)),\n",
        "                key = lambda e: -abs(e[1])):\n",
        "    if e[1] != 0:\n",
        "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJcIVv2ZO_l8",
        "outputId": "ed9a9cf6-ca0a-47a3-f15c-c54202eafc6e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crime dataset\n",
            "lasso regression linear model intercept: 1186.612061998579\n",
            "lasso regression linear model coeff:\n",
            "[    0.       0.      -0.    -168.18    -0.      -0.       0.     119.69\n",
            "     0.      -0.       0.    -169.68    -0.       0.      -0.       0.\n",
            "     0.       0.      -0.      -0.       0.      -0.       0.       0.\n",
            "   -57.53    -0.      -0.       0.     259.33    -0.       0.       0.\n",
            "     0.      -0.   -1188.74    -0.      -0.      -0.    -231.42     0.\n",
            "  1488.37     0.      -0.      -0.      -0.       0.       0.       0.\n",
            "     0.       0.      -0.       0.      20.14     0.       0.       0.\n",
            "     0.       0.     339.04     0.       0.     459.54    -0.       0.\n",
            "   122.69    -0.      91.41     0.      -0.       0.       0.      73.14\n",
            "     0.      -0.       0.       0.      86.36     0.       0.       0.\n",
            "  -104.57   264.93     0.      23.45   -49.39     0.       5.2      0.  ]\n",
            "Non-zero features: 20\n",
            "R-squared score (training): 0.631\n",
            "R-squared score (test): 0.624\n",
            "\n",
            "Features with non-zero weight (sorted by absolute magnitude):\n",
            "\tPctKidsBornNeverMar, 1488.365\n",
            "\tPctKids2Par, -1188.740\n",
            "\tHousVacant, 459.538\n",
            "\tPctPersDenseHous, 339.045\n",
            "\tNumInShelters, 264.932\n",
            "\tMalePctDivorce, 259.329\n",
            "\tPctWorkMom, -231.423\n",
            "\tpctWInvInc, -169.676\n",
            "\tagePct12t29, -168.183\n",
            "\tPctVacantBoarded, 122.692\n",
            "\tpctUrban, 119.694\n",
            "\tMedOwnCostPctIncNoMtg, -104.571\n",
            "\tMedYrHousBuilt, 91.412\n",
            "\tRentQrange, 86.356\n",
            "\tOwnOccHiQuart, 73.144\n",
            "\tPctEmplManu, -57.530\n",
            "\tPctBornSameState, -49.394\n",
            "\tPctForeignBorn, 23.449\n",
            "\tPctLargHouseFam, 20.144\n",
            "\tPctSameCity85, 5.198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos perceber que a Lasso força alguns coeficientes a ser zero, Isso ajuda a evitar problemas de overfitting, mas também ajuda a selecionar automaticamente as features mais importantes. Isso geralmente resulta em melhores previsões e modelos mais robustos, mas pode resultar em uma perda ligeira de precisão se os coeficientes são reduzidos demais."
      ],
      "metadata": {
        "id": "UeOivFCLR5Qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso regression with regularization parameter: alpha\n",
        "Da mesma forma que fizemos com Ridge vamos fazer aqui, usar o alpha para encontrar o melhor numeros de features a se manter de forma que obtemos o modelo que generaliza melhor. "
      ],
      "metadata": {
        "id": "si9El934ScSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Lasso regression: effect of alpha regularization\\n\\\n",
        "parameter on number of features kept in final model\\n')\n",
        "\n",
        "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
        "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
        "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
        "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
        "    \n",
        "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
        "r-squared test: {:.2f}\\n'\n",
        "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fh9asrOPw6R",
        "outputId": "9651aaa8-630a-4f6a-8976-60f6672654e3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso regression: effect of alpha regularization\n",
            "parameter on number of features kept in final model\n",
            "\n",
            "Alpha = 0.50\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 1.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 2.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 3.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 5.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 10.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 20.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n",
            "Alpha = 50.00\n",
            "Features kept: 0, r-squared training: 0.00, r-squared test: -0.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial regression\n",
        "Polynomial e uma função que cria novas caracteristicas elevando a potencia das caracteristicas originais(features) o objetivo e tentar capturar relações não lineares entre as features e a variavel resposta, e tentar melhorar a performance do modelo. "
      ],
      "metadata": {
        "id": "B82JcGsiUYbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_F1, y_F1,\n",
        "                                                   random_state = 0)\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print('linear model coeff (w): {}'\n",
        "     .format(linreg.coef_))\n",
        "print('linear model intercept (b): {:.3f}'\n",
        "     .format(linreg.intercept_))\n",
        "print('R-squared score (training): {:.3f}'\n",
        "     .format(linreg.score(X_train, y_train)))\n",
        "print('R-squared score (test): {:.3f}'\n",
        "     .format(linreg.score(X_test, y_test)))\n",
        "\n",
        "print('\\nAgora transformamos os dados de entrada originais para adicionar\\n\\\n",
        "recursos polinomiais até grau 2 (quadrático)\\n')\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_F1_poly = poly.fit_transform(X_F1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1,\n",
        "                                                   random_state = 0)\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "print('(poly deg 2) linear model coeff (w):\\n{}'\n",
        "     .format(linreg.coef_))\n",
        "print('(poly deg 2) linear model intercept (b): {:.3f}'\n",
        "     .format(linreg.intercept_))\n",
        "print('(poly deg 2) R-squared score (training): {:.3f}'\n",
        "     .format(linreg.score(X_train, y_train)))\n",
        "print('(poly deg 2) R-squared score (test): {:.3f}\\n'\n",
        "     .format(linreg.score(X_test, y_test)))\n",
        "\n",
        "print('\\nA adição de muitos recursos polinomiais geralmente leva a\\n\\\n",
        "overfitting, por isso geralmente usamos recursos polinomiais em combinação\\n\\\n",
        "com regressão que tem uma penalidade de regularização, como ridge\\n\\\n",
        "regressão.\\n')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1,\n",
        "                                                   random_state = 0)\n",
        "linreg = Ridge().fit(X_train, y_train)\n",
        "\n",
        "print('(poly deg 2 + ridge) linear model coeff (w):\\n{}'\n",
        "     .format(linreg.coef_))\n",
        "print('(poly deg 2 + ridge) linear model intercept (b): {:.3f}'\n",
        "     .format(linreg.intercept_))\n",
        "print('(poly deg 2 + ridge) R-squared score (training): {:.3f}'\n",
        "     .format(linreg.score(X_train, y_train)))\n",
        "print('(poly deg 2 + ridge) R-squared score (test): {:.3f}'\n",
        "     .format(linreg.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzBIwl7cUcyH",
        "outputId": "82ee1e13-d704-4f5f-84cc-243da1cb4ce4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear model coeff (w): [ 4.42  6.    0.53 10.24  6.55 -2.02 -0.32]\n",
            "linear model intercept (b): 1.543\n",
            "R-squared score (training): 0.722\n",
            "R-squared score (test): 0.722\n",
            "\n",
            "Agora transformamos os dados de entrada originais para adicionar\n",
            "recursos polinomiais até grau 2 (quadrático)\n",
            "\n",
            "(poly deg 2) linear model coeff (w):\n",
            "[ 3.41e-12  1.66e+01  2.67e+01 -2.21e+01  1.24e+01  6.93e+00  1.05e+00\n",
            "  3.71e+00 -1.34e+01 -5.73e+00  1.62e+00  3.66e+00  5.05e+00 -1.46e+00\n",
            "  1.95e+00 -1.51e+01  4.87e+00 -2.97e+00 -7.78e+00  5.15e+00 -4.65e+00\n",
            "  1.84e+01 -2.22e+00  2.17e+00 -1.28e+00  1.88e+00  1.53e-01  5.62e-01\n",
            " -8.92e-01 -2.18e+00  1.38e+00 -4.90e+00 -2.24e+00  1.38e+00 -5.52e-01\n",
            " -1.09e+00]\n",
            "(poly deg 2) linear model intercept (b): -3.206\n",
            "(poly deg 2) R-squared score (training): 0.969\n",
            "(poly deg 2) R-squared score (test): 0.805\n",
            "\n",
            "\n",
            "A adição de muitos recursos polinomiais geralmente leva a\n",
            "overfitting, por isso geralmente usamos recursos polinomiais em combinação\n",
            "com regressão que tem uma penalidade de regularização, como ridge\n",
            "regressão.\n",
            "\n",
            "(poly deg 2 + ridge) linear model coeff (w):\n",
            "[ 0.    2.23  4.73 -3.15  3.86  1.61 -0.77 -0.15 -1.75  1.6   1.37  2.52\n",
            "  2.72  0.49 -1.94 -1.63  1.51  0.89  0.26  2.05 -1.93  3.62 -0.72  0.63\n",
            " -3.16  1.29  3.55  1.73  0.94 -0.51  1.7  -1.98  1.81 -0.22  2.88 -0.89]\n",
            "(poly deg 2 + ridge) linear model intercept (b): 5.418\n",
            "(poly deg 2 + ridge) R-squared score (training): 0.826\n",
            "(poly deg 2 + ridge) R-squared score (test): 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQuBn5ZAUda5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}